{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import re\n",
    "\n",
    "# Load Raw Data\n",
    "inputDF = pd.read_excel('loan_default_data.xlsx')\n",
    "\n",
    "# Drop irrelevent columns\n",
    "# 1) Unnamed Column: there are no details provided for these columns\n",
    "unnamed_col = [i for i in inputDF.columns if 'unnamed' in i.lower()]\n",
    "inputDF.drop(unnamed_col, axis=1, inplace=True)\n",
    "\n",
    "# 2) ID Column: IDs are randomly (or increasing continuously) assigned numbers\n",
    "# it has no correlation to the decision\n",
    "id_col = ['id', 'member_id']\n",
    "inputDF.drop(id_col, axis=1, inplace=True)\n",
    "\n",
    "# 3) zip_code and address_state\n",
    "# we might be able to include these columns if we can find a suitable way to group the states into fewer groups\n",
    "# as for now, I will drop this\n",
    "id_col = ['zip_code', 'address_state']\n",
    "inputDF.drop(id_col, axis=1, inplace=True)\n",
    "\n",
    "# 4) loan_status\n",
    "# i am not quite understand this column, but seems like repay_fail depends on this column\n",
    "# e.g.: Fully Paid  -> repay_fail False\n",
    "#       Charged Off -> repay_fail True\n",
    "# since this columns seems highly correlated to the target variable, I will drop this\n",
    "inputDF.drop('loan_status', axis=1, inplace=True)\n",
    "\n",
    "# 5) loan_amount, funded_amount_investors and total_payment_investors\n",
    "# we only consider funded_amount which is the amount the client received\n",
    "# Investors should not affect client's repayment\n",
    "amt_list = ['loan_amount', 'funded_amount_investors', 'total_payment_investors']\n",
    "inputDF.drop(amt_list, axis=1, inplace=True)\n",
    "\n",
    "# 6) next_payment_date and months_since_last_delinquency: Too much missing values\n",
    "inputDF.drop(['next_payment_date','months_since_last_delinquency'], axis=1, inplace=True)\n",
    "\n",
    "# TEST: remove last_payment_amnt, total_received_interest, total_payment\n",
    "inputDF.drop(['last_payment_amnt','total_received_interest', 'total_payment'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# function to calculate months between dates\n",
    "def months_between(start_date, end_date):\n",
    "    try:\n",
    "        delta = relativedelta(end_date, start_date)\n",
    "        return delta.years * 12 + delta.months\n",
    "    except AssertionError:\n",
    "        return None\n",
    "\n",
    "\n",
    "# Modify Data\n",
    "# 1) change term to int column\n",
    "inputDF['term'] = inputDF['term'].apply(lambda x: re.search('\\d+',x).group()).astype(int)\n",
    "\n",
    "# 2) change home_ownership value 'NONE' to None\n",
    "inputDF['home_ownership'] = inputDF['home_ownership'].replace('NONE', None)\n",
    "\n",
    "# 3) split verification_status to verified and source_verified (bool columns instead of category)\n",
    "# Not Verified:     verified: False     source_verified: False\n",
    "# Verified:         verified: True      source_verified: False\n",
    "# Source Verified:  verified: True      source_verified: True\n",
    "inputDF['verified'] = inputDF['verification_status'].isin(['Verified', 'Source Verified'])\n",
    "inputDF['source_verified'] = inputDF['verification_status'].isin(['Source Verified'])\n",
    "# drop verification_status column\n",
    "inputDF.drop('verification_status', axis=1, inplace=True)\n",
    "\n",
    "# 4) Group employment_length into quantiles\n",
    "# because \"more than 10 years\" has been grouped into 10+, this is no longer continuous\n",
    "emp_year = inputDF['employment_length']\\\n",
    "    .dropna()\\\n",
    "    .replace('< 1 year', '0 year')\\\n",
    "    .replace('10+ years', '10 years')\\\n",
    "    .apply(lambda x: int(re.search('\\d+', x).group()))\n",
    "emp_q = emp_year.quantile([0.25,0.50,0.75])\n",
    "def getEmpLengthGroup(year):\n",
    "    if year==None:\n",
    "        return None\n",
    "    else:\n",
    "        if year <= emp_q[0.25]:\n",
    "            return f'0 - {int(emp_q[0.25])}'\n",
    "        elif year <= emp_q[0.50]:\n",
    "            return f'{int(emp_q[0.25])+1} - {int(emp_q[0.50])}'\n",
    "        elif year <= emp_q[0.75]:\n",
    "            return f'{int(emp_q[0.50])+1} - {int(emp_q[0.75])}'\n",
    "        else:\n",
    "            return f'{int(emp_q[0.75])+1}+'\n",
    "inputDF['employment_length_group'] = emp_year.apply(getEmpLengthGroup)\n",
    "# drop employment_length column\n",
    "inputDF.drop('employment_length', axis=1, inplace=True)\n",
    "\n",
    "# 5) Change repay_fail column dtype to bool\n",
    "inputDF['repay_fail'] = inputDF['repay_fail'].astype(bool)\n",
    "\n",
    "# 6) calculate Maturity Date\n",
    "inputDF['maturity_date'] = inputDF.apply(lambda x: x['issue_date'] + relativedelta(months=x['term']), axis=1)\n",
    "\n",
    "# 7) calculate Balance in percentage (funded_amount - total_received_principal)\n",
    "# update: looks like this variable is highly correlated to repay_fail, probably because this is historical data\n",
    "# if there are balance amount unpaid, it is already a sign of failed repayment\n",
    "# inputDF['balance_percentage'] = (inputDF['funded_amount'] - inputDF['total_received_principal']) / inputDF['funded_amount']\n",
    "# inputDF['balance_percentage'] = inputDF['balance_percentage'].apply(lambda x: round(x, 2))\n",
    "# Dropping total_received_principal as well\n",
    "inputDF.drop('total_received_principal', axis=1, inplace=True)\n",
    "\n",
    "# 8) calculate all date columns in terms of months, using last_credit_pull_date as reference date\n",
    "inputDF['months_to_maturity'] = inputDF\\\n",
    "    .apply(lambda x: months_between(x['last_credit_pull_date'],x['maturity_date']), axis=1)\n",
    "inputDF.loc[inputDF['months_to_maturity'] < 0, 'months_to_maturity'] = 0\n",
    "inputDF['months_since_issued'] = inputDF\\\n",
    "    .apply(lambda x: months_between(x['issue_date'],x['last_credit_pull_date']), axis=1)\n",
    "inputDF['months_since_first_credit'] = inputDF\\\n",
    "    .apply(lambda x: months_between(x['earliest_credit_line'],x['last_credit_pull_date']), axis=1)\n",
    "inputDF['months_since_last_payment'] = inputDF\\\n",
    "    .apply(lambda x: months_between(x['last_payment_date'],x['last_credit_pull_date']), axis=1)\n",
    "\n",
    "# 9) few valuse in revolving_utillization is in different format\n",
    "# Need to convert to float\n",
    "def convertStrPercentage(val):\n",
    "    try:\n",
    "        # NOTE: the double quotation marks is a unique character (” != \" and “ != \")\n",
    "        val = val.replace('”', '').replace('“', '').replace('%', '')\n",
    "        return float(val)/100\n",
    "    except:\n",
    "        return val\n",
    "inputDF['revolving_utillization'] = inputDF['revolving_utillization'].apply(convertStrPercentage)\n",
    "\n",
    "# 10) too many purpose categories, map purpose categories into high/low risk\n",
    "# we can use a boolean column here, using 'high_risk_purpose' column with value True or False\n",
    "# I dont have reliable data to classify each purpose's risk level,\n",
    "# So for now I categorize the following purpose as high risk\n",
    "#   Debt Consolidation and Credit Card:     This usually means the client has huge debt\n",
    "#   Small Business:                         businesses have probability to flop\n",
    "#   Medical:                                Applying loans for medical bill might indicate that the client has health issues,\n",
    "#                                           and possibility of \"unable to work\" condition\n",
    "highRiskMap = {\n",
    "    'major_purchase': False,\n",
    "    'other': False,\n",
    "    'debt_consolidation': True,\n",
    "    'credit_card': True,\n",
    "    'small_business': True,\n",
    "    'medical': True,\n",
    "    'wedding': False,\n",
    "    'car': False,\n",
    "    'home_improvement': False,\n",
    "    'educational': False,\n",
    "    'vacation': False,\n",
    "    'house': False,\n",
    "    'moving': False,\n",
    "    'renewable_energy': False\n",
    "}\n",
    "inputDF['high_risk_purpose'] = inputDF['purpose'].map(highRiskMap)\n",
    "inputDF.drop('purpose', axis=1, inplace=True)\n",
    "\n",
    "# TEST remove datetime col\n",
    "dtcol = ['issue_date','earliest_credit_line','last_payment_date','last_credit_pull_date','maturity_date']\n",
    "inputDF.drop(dtcol, axis=1, inplace=True)\n",
    "# TEST remove all month column\n",
    "mcol = ['months_to_maturity','months_since_issued','months_since_first_credit','months_since_last_payment']\n",
    "inputDF.drop(mcol, axis=1, inplace=True)\n",
    "\n",
    "# Drop rows with missing values\n",
    "inputDF.dropna(inplace=True)\n",
    "\n",
    "# # One-hot encode categorical columns\n",
    "inputDF = pd.get_dummies(inputDF, columns=['home_ownership', 'employment_length_group'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We still have a lot of variable, this will check if any variables are correlated\n",
    "c = inputDF.corr()\n",
    "\n",
    "# reduce variable that are highly correlated\n",
    "# funded_amount and installment\n",
    "inputDF.drop('installment', axis=1, inplace=True)\n",
    "\n",
    "# no_total_account and no_open_account\n",
    "inputDF.drop('no_total_account', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6327   20]\n",
      " [1127   11]]\n",
      "0.8467601870407482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\epulr\\Downloads\\Python Technical Assessment\\Python Technical Assessment\\env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = inputDF.drop('repay_fail', axis=1)\n",
    "y = inputDF['repay_fail']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "# Train a logistic regression model\n",
    "model = LogisticRegression(max_iter=100000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Test\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Still getting Evalutions Exceeds Limit, max_iter already high, might need to check if any more variable can be dropped\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(accuracy_score(y_test,y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
